services:
  custom_model_server:
    image: tensorflow/serving:latest
    container_name: custom_model_server
    ports:
      - "8501:8501"            # REST
    volumes:
      - ./models:/models
    command: >
      --model_config_file=./models/models.config
      --rest_api_port=8501

  webapp:
    build:
      context: .
      dockerfile: webapp.Dockerfile
    container_name: webapp
    environment:
      - TF_URL=http://custom_model_server:8501/v1/models/custom_model:predict
      - TF_2_URL=http://custom_model_server:8501/v1/models/feature_extraction_model:predict
    ports:
      - "8000:8000"
    depends_on:
      - custom_model_server
